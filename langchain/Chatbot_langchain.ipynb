{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "562b9d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "88343566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000212DBDF8090>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000212DD413250>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import certifi\n",
    "os.environ['SSL_CERT_FILE'] = certifi.where()\n",
    "from langchain_groq import ChatGroq\n",
    "model = ChatGroq(model=\"Gemma2-9b-It\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50247d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Devansh, it's nice to meet you!\\n\\nAs a Data Scientist, what are you currently working on? Do you have any interesting projects you'd like to talk about?  \\n\\nI'm always interested in learning more about the work data scientists do.  Perhaps I can even help with some tasks or provide information related to your projects.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 76, 'prompt_tokens': 22, 'total_tokens': 98, 'completion_time': 0.138181818, 'prompt_time': 0.002149688, 'queue_time': 0.24142572599999998, 'total_time': 0.140331506}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--d3e75be1-8d1d-4868-baa8-cba39d1a8f7a-0', usage_metadata={'input_tokens': 22, 'output_tokens': 76, 'total_tokens': 98})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Devansh and I am a Data Scientist\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You said your name is Devansh, and you are a Data Scientist!  üòä \\n\\nIs there anything else you'd like to tell me about yourself or your work?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 117, 'total_tokens': 156, 'completion_time': 0.070909091, 'prompt_time': 0.010180398, 'queue_time': 0.343309592, 'total_time': 0.081089489}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--35215777-1ff9-4747-8158-464e6173a45a-0', usage_metadata={'input_tokens': 117, 'output_tokens': 39, 'total_tokens': 156})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content = \"Hi my name is Devansh and i am a Data Scientist\"),\n",
    "        AIMessage(content=\"Hi Devansh, it's nice to meet you!\\n\\nAs a Data Scientist, what are you currently working on? Do you have any interesting projects you'd like to talk about?  \\n\\nI'm always interested in learning more about the work data scientists do.  Perhaps I can even help with some tasks or provide information related to your projects.\\n\"),\n",
    "        HumanMessage(content=\"Hey, what is my name and what do i do?\")\n",
    "        \n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81b9e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "## message history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "store={}\n",
    "def get_session_history(session_id:str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory() # whatever chat is happening it should be stored in the current session id\n",
    "    return store[session_id]\n",
    "with_message_hsitory = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cacc0a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c969f9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = with_message_hsitory.invoke(\n",
    "    [HumanMessage(content='Hi I am Devansh and i am a Data Sientist')],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e2d66e06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hey Devansh, that's awesome! \\n\\nWhat kind of data science work are you into?  Do you specialize in a particular area like machine learning, deep learning, or data visualization?  \\n\\nI'm always eager to learn more about what people are doing in the field. üòä \\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6255cf0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I have no access to your personal information, including your name. If you'd like to tell me your name, I'd be happy to know!\\n\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config1 = {\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "response = with_message_hsitory.invoke(\n",
    "    [HumanMessage(content=\"What is my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155d83c0",
   "metadata": {},
   "source": [
    "#### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9c8f6686",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55e05ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Devansh, it's nice to meet you! \\n\\nI'm happy to help with any questions you have. What can I do for you today? üòä  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 32, 'total_tokens': 71, 'completion_time': 0.070909091, 'prompt_time': 0.002319314, 'queue_time': 0.24861039800000004, 'total_time': 0.073228405}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run--229fbf88-b1c7-496e-bf0c-063be953c6d6-0', usage_metadata={'input_tokens': 32, 'output_tokens': 39, 'total_tokens': 71})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi my name is Devansh\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "22587a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_hsitory = RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5e07dd49",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response = with_message_hsitory.invoke(\n",
    "    [HumanMessage(content=\"Hi my name is Devansh\")],\n",
    "    config = config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df784576",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi Devansh, it's nice to meet you!\\n\\nWhat can I do for you today? üòä  \\n\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82785d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "## adding complexity\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"You are a helpful assistant. Answer all the questions to the best of your ability in {language}.\"),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "84e29e54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'¬°Hola Devansh! \\n\\nMucho gusto en conocerte. ¬øC√≥mo puedo ayudarte hoy? \\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Devansh\")],\"language\":\"Spanish\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ddefc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_hsitory = RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "67d4979a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Bonjour Devansh !\\n\\nEnchant√© de te rencontrer. Comment puis-je t'aider aujourd'hui ? \\n\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "resp = with_message_hsitory.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"Hi my name is Devansh\")],\"language\":\"French\"},\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3aa86ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ton nom est Devansh.  \\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp = with_message_hsitory.invoke(\n",
    "    {\"messages\":[HumanMessage(content=\"What is my name\")],\"language\":\"French\"},\n",
    "    config=config\n",
    ")\n",
    "resp.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795279bd",
   "metadata": {},
   "source": [
    "#### Managing the conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "67fe2a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good AI asistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"what's 2 + 2\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='Having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='Yes! Bring it on', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 45,\n",
    "    strategy='last',\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial = False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good AI asistant\"),\n",
    "    HumanMessage(content=\"Hi! I am Devansh\"),\n",
    "    AIMessage(content=\"Hi!\"),\n",
    "    HumanMessage(content=\"I like dark chocolates\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"what's 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"Having fun?\"),\n",
    "    AIMessage(content=\"Yes! Bring it on\")\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "77d15a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to your personal preferences like your favorite ice cream flavor. \\n\\nWhat's your favorite flavor?  üç¶üòã\\n\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "chain= (\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt\n",
    "    |model\n",
    ")\n",
    "response = chain.invoke({\"messages\":messages + [HumanMessage(content=\"What ice cream do i like?\")],\n",
    "              \"language\":\"English\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce181e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations. If you'd like to ask me a math problem, I'm happy to help! üòä  \\n\\n\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response = chain.invoke({\"messages\":messages + [HumanMessage(content=\"What math problem did i ask\")],\n",
    "              \"language\":\"English\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0406b94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"You haven't asked me any problems yet! üòÑ \\n\\nWhat can I help you with?\\n\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,get_session_history,input_messages_key=\"messages\",\n",
    ")\n",
    "config = {\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "\n",
    "response = chain.invoke({\"messages\":messages + [HumanMessage(content=\"What problem did i ask\")],\n",
    "              \"language\":\"English\"},\n",
    "              config=config,)\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9316a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
